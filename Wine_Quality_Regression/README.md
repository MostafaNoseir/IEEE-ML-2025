# ğŸ’ Diamond Price Prediction

## ğŸ“ Overview
This project presents a comprehensive regression analysis to predict **diamond prices** using various linear models including **Linear Regression**, **Ridge**, **Lasso**, and **ElasticNet**. The notebook follows a structured machine learning pipeline from exploratory data analysis to model evaluation.

---

## ğŸ“ Dataset
- **Source**: Diamonds dataset (53,940 records)
- **Features**:
  - `carat`, `cut`, `color`, `clarity`, `depth`, `table`, `x`, `y`, `z`
- **Target**: `price` (in US dollars)

---

## ğŸ” Workflow Summary

### 1. Data Exploration
- Loaded the dataset and viewed basic statistics (`shape`, `info()`, `describe()`)
- Identified categorical (`cut`, `color`, `clarity`) and numerical columns

### 2. Data Cleaning & Preprocessing
- âœ… Dropped unnecessary column: `Unnamed: 0`
- âœ… Removed duplicates
- âœ… Confirmed no missing values
- âœ… Visualized outliers with boxplots
- âœ… Removed outliers using IQR method
- âœ… Checked correlation with heatmap
- âœ… Dropped `depth` due to low correlation with target

### 3. Feature Engineering
- Applied **one-hot encoding** to categorical features (`cut`, `color`, `clarity`)
- Split data into **features (X)** and **target (y)**

### 4. Data Splitting & Scaling
- Split data into **training (80%)** and **testing (20%)** sets
- Scaled numeric features (`carat`, `table`, `x`, `y`, `z`) using `MinMaxScaler`

---

## ğŸ¤– Model Training & Evaluation

### ğŸ”¹ Linear Regression
- Trained on scaled data
- Achieved:
  - **RÂ² Score**: 0.93
  - **RMSE**: ~705
  - **Adjusted RÂ²**: 0.93
- Visualized actual vs predicted prices with a scatter plot

### ğŸ”¹ Ridge Regression
- Regularization parameter: `alpha=0.001`
- Achieved similar performance as basic linear regression

### ğŸ”¹ Lasso Regression
- `alpha=0.001`, `max_iter=10000`
- Performance nearly identical to Ridge

### ğŸ”¹ ElasticNet Regression
- `alpha=0.001`, `l1_ratio=0.8`
- Slightly lower performance:
  - **RÂ² Score**: 0.92
  - **RMSE**: ~716

---

## ğŸ“Š Results Comparison

| Model            | RÂ² Score | RMSE |
|------------------|----------|------|
| Linear Regression| 0.93     | 705  |
| Ridge            | 0.93     | 705  |
| Lasso            | 0.93     | 705  |
| ElasticNet       | 0.92     | 716  |

---

## âœ… Conclusion
- The **basic Linear Regression model** outperformed regularized models on this dataset.
- **Carat** had the highest coefficient, indicating it's the most influential feature.
- **Regularization** did not significantly improve model performance, possibly due to proper preprocessing and low multicollinearity.

---

## ğŸ§  Key Takeaways
- Removing outliers and proper encoding significantly improves model accuracy.
- Always validate if regularization is necessary â€” sometimes simpler models perform best.
